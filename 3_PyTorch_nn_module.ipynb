{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwfSuB73fp2RYoGT72yCv+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vasukondreddy/PyTorch/blob/main/3_PyTorch_nn_module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fFs8kEs7dTD"
      },
      "outputs": [],
      "source": [
        "# create model class\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "  def __init__(self,num_features): # constructor\n",
        "\n",
        "    super().__init__() # parent class constructor\n",
        "    self.linear = nn.Linear(num_features,1) # here 1 indicateds ou[ut features\n",
        "    self.sigmoid = nn.Sigmoid() # which squashes output values into a range between 0 and 1.\n",
        "    # sigmoid() Commonly used in binary classification to convert raw outputs to probabilities.\n",
        "\n",
        "  def forward(self,features): # This is the forward pass of the model, where input data goes through the layers.\n",
        "\n",
        "    out=self.linear(features)\n",
        "    out=self.sigmoid(out)\n",
        "\n",
        "    return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset\n",
        "\n",
        "features= torch.rand(10,5)\n",
        "\n",
        "# create model\n",
        "model=Model(features.shape[1]) # objct created\n",
        "\n",
        "# call model for forward pass\n",
        "#model.forward(features)\n",
        "model(features) # standard way to call model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9Vlb9hf-Pmv",
        "outputId": "d3ca774c-d55f-4563-be21-55333414e0ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6426],\n",
              "        [0.6598],\n",
              "        [0.6147],\n",
              "        [0.6478],\n",
              "        [0.6427],\n",
              "        [0.7027],\n",
              "        [0.6844],\n",
              "        [0.7013],\n",
              "        [0.6382],\n",
              "        [0.6414]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show model weights\n",
        "model.linear.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFlHcxe6-xQd",
        "outputId": "03265891-ca0a-4414-a9ce-9e39deed215c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0517, -0.2557,  0.4084,  0.1636,  0.3288]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_x4LTSw_AzO",
        "outputId": "68c173df-8d1a-4b76-c2f9-52f24cea77e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0.2971], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wQCFgFn_Rc_",
        "outputId": "9ea17bd2-b88d-4634-b9c9-8446b6f6a6f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visulaize the network\n",
        "from torchinfo import summary\n",
        "summary(model,input_size=(10,5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU7AuH6n_X0g",
        "outputId": "bccff20c-d129-40f9-fbfc-df034b7b411d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Model                                    [10, 1]                   --\n",
              "├─Linear: 1-1                            [10, 1]                   6\n",
              "├─Sigmoid: 1-2                           [10, 1]                   --\n",
              "==========================================================================================\n",
              "Total params: 6\n",
              "Trainable params: 6\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.00\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "\n",
        "  def __init__(self,num_features):\n",
        "\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(num_features,3)\n",
        "    self.relu = nn.ReLU() # activation for hidden layer\n",
        "# in this model we are taking 5inpus 3 hiden layers(use ReLU) hasa 3bias and output as 1\n",
        "    self.linear2 = nn.Linear(3,1)\n",
        "    self.sigmoid=nn.Sigmoid()\n",
        "\n",
        "  def forward(self,features):\n",
        "    out=self.linear1(features)\n",
        "    out=self.relu(out)\n",
        "    out=self.linear2(out)\n",
        "    out=self.sigmoid(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "eNed9gfR_jpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset\n",
        "\n",
        "features= torch.rand(10,5)\n",
        "\n",
        "# create model\n",
        "model=Model(features.shape[1]) # objct created\n",
        "\n",
        "# call model for forward pass\n",
        "#model.forward(features)\n",
        "model(features) # standard way to call model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo-kk5zYAwc4",
        "outputId": "b94926f2-6e4d-4e00-d413-7b1ecbdc7d11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6367],\n",
              "        [0.6259],\n",
              "        [0.6343],\n",
              "        [0.6307],\n",
              "        [0.6174],\n",
              "        [0.6272],\n",
              "        [0.6305],\n",
              "        [0.6270],\n",
              "        [0.6362],\n",
              "        [0.6204]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show model weights\n",
        "model.linear1.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpJOkE-XA27G",
        "outputId": "edde5fc1-35fb-4ea7-e462-510f4deefe17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0293,  0.2966, -0.0476, -0.3980,  0.0162],\n",
              "        [ 0.3787,  0.0300,  0.2446, -0.4438,  0.0337],\n",
              "        [ 0.2175, -0.2005, -0.3490,  0.2617, -0.1256]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear1.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7NwCGYOBfks",
        "outputId": "6758eca9-5fde-4b59-f51b-d817eb2ceeb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([-0.2601,  0.4071, -0.3805], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear2.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vxpdLybBiYc",
        "outputId": "c5ef4bbd-d2ce-4f39-db90-fb7e500f485c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.2370,  0.2093,  0.3729]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear2.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9sxTPH9CmCJ",
        "outputId": "979bab72-1ad4-45bc-88c1-cae9f284b57b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0.4320], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "summary (model,input_size=(10,5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9gmsRTgCpEW",
        "outputId": "c72437af-a49b-44be-b55d-464b53ad935e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Model                                    [10, 1]                   --\n",
              "├─Linear: 1-1                            [10, 3]                   18\n",
              "├─ReLU: 1-2                              [10, 3]                   --\n",
              "├─Linear: 1-3                            [10, 1]                   4\n",
              "├─Sigmoid: 1-4                           [10, 1]                   --\n",
              "==========================================================================================\n",
              "Total params: 22\n",
              "Trainable params: 22\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.00\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "\n",
        "  def __init__(self,num_features):\n",
        "\n",
        "    super().__init__()\n",
        "    ## Using Sequential Container to create model easily\n",
        "    self.network = nn.Sequential(\n",
        "        nn.Linear(num_features,3),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(3,1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self,features):\n",
        "    out=self.network(features)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "VfgpOWESDGvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset\n",
        "\n",
        "features= torch.rand(10,5)\n",
        "\n",
        "# create model\n",
        "model=Model(features.shape[1]) # objct created\n",
        "\n",
        "# call model for forward pass\n",
        "#model.forward(features)\n",
        "model(features) # standard way to call model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shr6vILBGHfL",
        "outputId": "f27b4dc6-4303-4762-8b76-922da2bf8942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6285],\n",
              "        [0.6067],\n",
              "        [0.6705],\n",
              "        [0.6126],\n",
              "        [0.5795],\n",
              "        [0.6108],\n",
              "        [0.5864],\n",
              "        [0.6001],\n",
              "        [0.5967],\n",
              "        [0.6291]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cg4-D2etGNCp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}